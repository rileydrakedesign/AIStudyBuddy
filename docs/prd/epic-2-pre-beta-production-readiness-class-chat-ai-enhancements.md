# Epic 2: Pre-Beta Production Readiness - Class Chat AI Enhancements

**Epic Goal**:
Deliver a polished, production-ready Class Chat AI MVP for beta launch with all critical bugs resolved, UX refined, RAG quality improved, authentication hardened, and infrastructure optimized for observability and scale.

**Integration Requirements**:
- All changes must maintain backward compatibility with existing user data (no breaking schema changes)
- Deployment must follow phased approach (backend â†’ low-risk frontend â†’ high-risk frontend) to mitigate no-staging-environment risk
- Each story must include verification that existing functionality remains intact (regression testing focus)
- Feature flags required for high-risk features (LLM reranking, OCR) to enable rapid rollback

**Success Criteria**:
- All P0 (critical) and P1 (high) issues from ROUGH_FIXES.md resolved
- Beta launch checklist 100% complete (manual testing, Google OAuth verified, logs structured)
- No regressions in core flows (signup â†’ upload â†’ chat â†’ citation â†’ verification)
- Performance targets met (response times, ingestion times, UI interactions)

---

## Story 2.1: Infrastructure Foundation - Logging, Config, and Code Cleanup

As a **developer**,
I want **centralized configuration, improved logging, and clean codebase**,
so that **I can debug issues quickly during beta and maintain code quality**.

### Acceptance Criteria

**Functional Requirements**:
1. Python service uses centralized `config.py` for all environment variables
2. Python logger captures all log levels (debug, info, warning, error) correctly
3. Node logger uses consistent structured format with improved readability
4. All log entries include `user_id` and `session_id` when available
5. Unused imports removed from backend (Node and Python)
6. Code linting identifies and fixes unused variables, dead code

**Integration Verification**:
1. Existing MongoDB connection continues to work with centralized config
2. Existing OpenAI API calls continue to work with config module
3. Log output is parseable by Heroku log aggregation (JSON format in production)
4. No performance degradation from logging changes

**Quality Requirements**:
5. Config module validates required env vars on startup and fails fast with clear errors
6. Log format includes timestamp, level, user_id, session_id, message (consistent structure)
7. Backend LOC reduced by at least 5% (removing dead code)

### Integration Verification

**IV1: Existing Functionality Verification**
- MongoDB queries execute successfully using `config.MONGO_CONNECTION_STRING`
- OpenAI embeddings and generation calls work using `config.OPENAI_API_KEY`
- Redis connection establishes using `config.REDIS_URL`

**IV2: Integration Point Verification**
- Heroku logs show structured JSON format in production environment
- Local development logs show pretty-printed format for readability
- All API endpoints log requests with user_id context (test with authenticated user)

**IV3: Performance Impact Verification**
- Baseline response time measured before changes
- Post-deployment response time within 5% of baseline (logging overhead negligible)
- Memory usage reduced due to removed imports (measure via Heroku metrics)

### Technical Notes

- **Integration Approach**: Create `config.py` as single source of truth, refactor all `os.getenv()` calls to import from config
- **Existing Pattern Reference**: Follow architecture.md logging patterns (Pino for Node, Loguru for Python)
- **Key Constraints**: Must not break existing environment variable names (backward compatible)

### Definition of Done

- [ ] Centralized config module created and all services use it
- [ ] Python logger captures all levels, Node logger uses structured format
- [ ] User/session IDs present in 100% of relevant log entries
- [ ] Unused imports removed, code linting clean
- [ ] Deployed to Heroku, logs verified in production
- [ ] No regressions in existing API functionality

---

## Story 2.2: Authentication Hardening - Password Reset, Login Limiting, Delete Account

As a **user**,
I want **secure password reset, brute-force protection, and account deletion**,
so that **I can recover access if locked out and maintain control over my data**.

### Acceptance Criteria

**Functional Requirements**:
1. Password reset flow implemented (forgot password â†’ email with token â†’ reset form)
2. Login attempts rate-limited to max 5 per 15 minutes per email
3. Profile page email changes require verification email to new address
4. Profile page password changes require current password validation
5. Email confirmation link auto-redirects to chat page on success
6. Mobile email confirmation shows confirmation message without chat access
7. Delete account functionality with confirmation modal
8. Account deletion removes all user data (user, classes, docs, chunks, S3 files)

**Integration Verification**:
1. Mailgun sends password reset emails successfully
2. Password reset tokens expire after 1 hour and are single-use only
3. Login attempt counter resets after 15 minutes
4. Deleted user email is blocked from re-registration

**Quality Requirements**:
5. Password reset tokens are cryptographically random (UUID v4)
6. Account deletion is atomic (all-or-nothing transaction)
7. Delete account requires password re-entry before confirmation

### Integration Verification

**IV1: Existing Auth Functionality Verification**
- JWT-based login/signup continues to work unchanged
- Google OAuth flow continues to work unchanged
- Existing email verification flow remains functional

**IV2: Email Integration Verification**
- Password reset emails arrive within 1 minute (test across email providers)
- Email change verification emails arrive and update user record correctly
- All emails use existing Mailgun configuration and templates

**IV3: Data Deletion Verification**
- MongoDB user record deleted
- All classes associated with user deleted
- All documents (MongoDB records) deleted
- All chunks (study_materials2 collection) deleted
- All S3 files for user deleted
- All chat sessions deleted

### Technical Notes

- **Integration Approach**:
  - Add `passwordResetToken`, `passwordResetTokenExp`, `loginAttempts`, `loginAttemptResetAt` to User model
  - Create `/api/v1/user/forgot-password` and `/api/v1/user/reset-password` endpoints
  - Add `/api/v1/user/delete-account` endpoint with transaction logic
- **Existing Pattern Reference**: Follow email verification pattern in `user_confirm.ts` for password reset
- **Rollback Considerations**: If account deletion fails midway, log error and mark account for manual cleanup

### Definition of Done

- [ ] Password reset flow end-to-end tested
- [ ] Login attempt limiting blocks after 5 failures, unblocks after 15 minutes
- [ ] Email change requires verification, old email receives notification
- [ ] Password change requires current password, validates strength
- [ ] Email confirmation auto-redirects to chat (desktop) or shows mobile message
- [ ] Delete account removes all data, verified in MongoDB + S3
- [ ] No regressions in existing auth flows

---

## Story 2.3: RAG Quality - Citation Clustering Fix & Retrieval Improvements

As a **student**,
I want **clean, accurate citations (max 3-5 per answer) and better retrieval quality**,
so that **I can trust the AI's sources and verify information easily**.

### Acceptance Criteria

**Functional Requirements**:
1. In-text citations limited to max 3-5 unique sources per answer
2. Citation numbering matches actual unique sources used, not total chunks
3. Citations renumbered sequentially and validated against response content
4. Citation clustering bug resolved (no more `[1][2][3][4][5][13][15]...`)
5. Hybrid retrieval: semantic search + summary fallback when similarity below threshold
6. Query refinement suggestions provided when no relevant chunks found
7. Document summaries excluded from semantic search for specific questions
8. LLM-based reranking available via feature flag `ENABLE_LLM_RERANKING`

**Integration Verification**:
1. Existing semantic search continues to work with new citation logic
2. Chat history and chunk references maintained in MongoDB correctly
3. Frontend citation rendering displays new format correctly

**Quality Requirements**:
4. Citation renumbering executes in <100ms
5. LLM reranking (if enabled) adds max 500ms latency
6. Query refinement suggestions are contextual, not generic

### Integration Verification

**IV1: Existing RAG Pipeline Verification**
- MongoDB vector search returns results correctly
- OpenAI generation produces answers with inline citations
- Chunk deduplication logic works (no duplicate pages)

**IV2: Citation Integration Verification**
- Frontend parses renumbered citations and renders as clickable links
- Citation metadata matches chunks returned in response
- Document download URLs (S3 pre-signed) work correctly

**IV3: Retrieval Quality Verification**
- Test with 10 diverse queries (factual, conceptual, quote-finding)
- Verify max 3-5 citations in each response
- Verify summary fallback triggers when no chunks found
- Verify refinement suggestions appear for no-hit scenarios

### Technical Notes

- **Integration Approach**:
  - Modify `_renumber_citations()` in `semantic_search.py`
  - Add chunk deduplication by `(doc_id, citation_number)` before citation assignment
  - Implement summary fallback in `process_semantic_search()`
  - Add LLM reranking as optional post-processing step
- **Existing Pattern Reference**: Current citation logic in `get_file_citation()` and `_renumber_citations()`
- **Testing Focus**: Edge cases (duplicate chunks, no-hit, very long answers with many sources)

### Definition of Done

- [ ] Upload 5 test documents, query each, verify max 3-5 citations per response
- [ ] No citation clustering (no `[1][2][3][4][5]...` patterns)
- [ ] Summary fallback works (query irrelevant topic, get summary instead of "no results")
- [ ] Query refinement suggestions appear for no-hit scenarios
- [ ] LLM reranking feature flag works (enable â†’ improved results, disable â†’ faster responses)
- [ ] No regressions in existing chat functionality

---

## Story 2.4: Document Processing - Section Metadata, Suggested Queries, Multi-Format Support

As a **student**,
I want **better document organization, helpful query suggestions, and support for Word/PowerPoint files**,
so that **I can upload all my study materials and get started quickly**.

### Acceptance Criteria

**Functional Requirements**:
1. Section/subsection metadata extracted during PDF chunking
2. Section metadata stored with each chunk (`section_title`, `section_hierarchy`)
3. 5 suggested queries generated per document during ingestion
4. Suggested queries stored in document metadata and displayed in chat UI
5. DOCX file uploads supported with text extraction
6. PPTX file uploads supported with text/slide extraction
7. OCR supported for scanned PDFs and image uploads
8. File type validation rejects unsupported formats with clear errors

**Integration Verification**:
1. Existing PDF ingestion continues to work with new metadata extraction
2. MongoDB chunk schema handles new fields
3. Document model handles new `suggestedQueries` and `fileType` fields
4. S3 upload supports new file types

**Quality Requirements**:
5. Suggested query generation adds <20% to ingestion time
6. Section metadata extraction scales to 500-page documents
7. OCR accuracy >80% on printed text, >60% on clear handwriting

### Integration Verification

**IV1: Existing Ingestion Pipeline Verification**
- PDF chunking and embedding continues to work
- RQ job queue processes ingestion jobs correctly
- WebSocket `document-ready` event fires when processing completes

**IV2: New Format Integration Verification**
- DOCX text extraction produces clean markdown
- PPTX slide extraction preserves structure
- OCR processes scanned PDF and returns searchable text

**IV3: Metadata Storage Verification**
- Section metadata appears in MongoDB chunks
- Suggested queries appear in document metadata
- Frontend receives suggested queries in upload response

### Technical Notes

- **Integration Approach**:
  - Modify `load_data.py` to extract headings using PyMuPDF or regex
  - Add `generate_suggested_queries()` function calling OpenAI
  - Create `docx_processor.py`, `pptx_processor.py`, `ocr_processor.py` modules
  - Add file type detection in upload route
- **Existing Pattern Reference**: Current PDF chunking in `load_data.py`
- **Rollback Considerations**: Feature flags `ENABLE_OCR` and file type validation allow disabling new formats

### Definition of Done

- [ ] Upload PDF, verify section metadata extracted and stored in chunks
- [ ] Upload PDF, verify 5 suggested queries generated and displayed in UI
- [ ] Upload DOCX, verify ingestion completes and text is searchable
- [ ] Upload PPTX, verify ingestion completes and slide text is searchable
- [ ] Upload scanned PDF or image, verify OCR extracts text (if `ENABLE_OCR=true`)
- [ ] Upload unsupported format, verify clear error message
- [ ] No regressions in existing PDF ingestion

---

## Story 2.5: Study Material Generation - Formatting, Context Awareness, and Persistence

As a **student**,
I want **well-formatted study guides, context-aware generation, and ability to save materials**,
so that **I can create reusable study resources and access them later**.

### Acceptance Criteria

**Functional Requirements**:
1. Study guides follow strict Q&A structure with markdown headings
2. Study guide generation supports context-aware scoping
3. Summaries, study guides, and quotes rendered with special formatting
4. Each response type has visual indicators (icons, borders, backgrounds)
5. Users can save generated materials (summaries, study guides, quotes)
6. Saved materials appear in sidebar under selected class
7. Saved materials are editable via markdown editor
8. Saved materials track metadata (creation date, source docs, query)
9. Users can delete saved materials with confirmation

**Integration Verification**:
1. Existing study guide generation route continues to work
2. MongoDB `saved_materials` collection stores new saves correctly
3. Frontend renders special formatting using existing markdown pipeline

**Quality Requirements**:
4. Study guide generation completes within 15s for class-level summaries
5. Save operation completes within 1s
6. Markdown editor supports syntax highlighting and preview mode

### Integration Verification

**IV1: Existing Generation Functionality Verification**
- Study guide generation route produces output
- Summary generation works for document and class scopes
- Quote finding returns verbatim quotes with citations

**IV2: Saved Materials Integration Verification**
- Save button triggers API call to `/api/v1/materials/save`
- MongoDB `saved_materials` collection receives new document
- Sidebar queries and displays saved materials for selected class
- Edit modal loads saved material content and allows updates

**IV3: Special Formatting Verification**
- Study guide response has blue border + book icon
- Summary response has green border + document icon
- Quote response has purple border + quote icon
- Save button appears on all special responses

### Technical Notes

- **Integration Approach**:
  - Modify study guide prompt in `prompts.json` to enforce strict structure
  - Add context filtering to retrieval
  - Create `SpecialResponseCard.tsx` component for formatted rendering
  - Create `SaveMaterialModal.tsx` for save dialog
  - Add `/api/v1/materials/*` routes in Node backend
  - Create `savedMaterial.ts` Mongoose model
- **Existing Pattern Reference**: Chat message rendering in `chatItem.tsx`
- **Testing Focus**: Context-aware scoping (verify "Markov chains" doesn't return entire class summary)

### Definition of Done

- [ ] Generate study guide, verify strict Q&A structure
- [ ] Generate context-aware study guide, verify only relevant content returned
- [ ] Study guide response has special formatting (border, icon, save button)
- [ ] Click save button, enter title, verify material saved to MongoDB
- [ ] Saved material appears in sidebar under correct class
- [ ] Edit saved material, verify changes persist
- [ ] Delete saved material, verify removed from MongoDB and sidebar
- [ ] No regressions in existing chat functionality

---

## Story 2.6: UI/UX Polish - Sidebar Redesign, Formula Fixes, Mobile Blocking

As a **student**,
I want **intuitive navigation, clean design, and proper mobile handling**,
so that **I can focus on studying without UI frustrations**.

### Acceptance Criteria

**Functional Requirements**:
1. Sidebar includes class dropdown selector at top
2. Sidebar displays Documents, Chats, and Saved Materials for selected class
3. "Recent Chats" section shows chats across all classes with class badges
4. Sidebar is responsive and maintains state across navigation
5. UI uses softer edges, animations, clean icons, bubble chat design
6. Formula rendering displays correctly without layout breaks
7. Document chat window maintains fixed size regardless of formula length
8. Toast notifications repositioned to bottom-right
9. Mobile devices show blocking page with helpful message

**Integration Verification**:
1. Existing class/document/chat data loads correctly in new sidebar
2. Class switching updates main content area
3. Formula rendering uses existing KaTeX pipeline

**Quality Requirements**:
4. Sidebar class selection renders in <200ms
5. Formula rendering gracefully degrades (shows LaTeX source if KaTeX fails)
6. Mobile blocking page displays on all mobile devices

### Integration Verification

**IV1: Existing Navigation Verification**
- Clicking document in sidebar opens document viewer
- Clicking chat in sidebar loads chat session
- Class data fetched from MongoDB and displayed correctly

**IV2: Sidebar State Verification**
- Selected class persists when navigating between chat and document viewer
- Expanded/collapsed sidebar sections maintain state
- Recent chats list updates when new chat created

**IV3: Mobile Blocking Verification**
- Access app from iPhone Safari, verify blocking page appears
- Access app from Android Chrome, verify blocking page appears
- Access app from desktop, verify normal app loads

### Technical Notes

- **Integration Approach**:
  - Create `ClassDropdown.tsx`, `SavedMaterialsList.tsx`, `RecentChatsList.tsx` components
  - Modify `Chat.tsx` to integrate new sidebar structure
  - Add mobile detection in `App.tsx`
  - Update CSS for softer edges, formula overflow
  - Reposition toast notifications (Material UI Snackbar)
- **Existing Pattern Reference**: Current sidebar in `Chat.tsx`
- **Testing Focus**: Responsive behavior at different screen sizes

### Definition of Done

- [ ] Sidebar displays class dropdown with all user classes
- [ ] Selecting class shows Documents, Chats, Saved Materials for that class
- [ ] Recent Chats section shows recent chats with class badges
- [ ] Sidebar state persists when switching between chat and document viewer
- [ ] UI has softer edges, smooth animations, clean icons
- [ ] Upload math-heavy PDF, verify formulas render without breaking layout
- [ ] Document chat window stays fixed size with long formulas
- [ ] Toast notifications appear at bottom-right
- [ ] Access from mobile, verify blocking page appears
- [ ] No regressions in existing navigation or UI functionality

---

## Story 2.7: Document Viewer Enhancement - Native Summary Toggle

As a **student**,
I want **quick access to document summaries in the viewer**,
so that **I can review key points without reading the entire PDF**.

### Acceptance Criteria

**Functional Requirements**:
1. Document chat page includes toggle buttons: [ðŸ“„ PDF | ðŸ“ Summary]
2. Summary view displays pre-generated markdown-formatted summary
3. Toggle maintains state when switching between documents in a session

**Integration Verification**:
1. Existing PDF viewer (react-pdf) continues to work
2. Summary fetched from MongoDB (is_summary=True chunk for doc_id)
3. Summary view uses existing markdown rendering pipeline

**Quality Requirements**:
4. Toggle switch renders in <100ms
5. Summary loads within 1s

### Integration Verification

**IV1: Existing Document Viewer Verification**
- PDF viewer displays documents correctly
- Page navigation works (clicking citations jumps to pages)

**IV2: Summary Retrieval Verification**
- MongoDB query fetches summary chunk correctly
- Summary text rendered as markdown with proper formatting
- No summary available shows helpful message

**IV3: Toggle State Verification**
- Toggle state persists when switching between documents
- Toggle state resets when leaving document viewer and returning

### Technical Notes

- **Integration Approach**:
  - Add toggle buttons to `DocumentChat.tsx` header
  - Create `SummaryView.tsx` component for markdown rendering
  - Add state variable `viewMode: "pdf" | "summary"` to track toggle
  - Fetch summary via new endpoint `/api/v1/documents/:docId/summary`
- **Existing Pattern Reference**: PDF viewer in `DocumentChat.tsx`
- **Testing Focus**: Toggle behavior with multiple documents in quick succession

### Definition of Done

- [ ] Toggle buttons appear in document viewer header
- [ ] Click "Summary" â†’ markdown summary displays
- [ ] Click "PDF" â†’ PDF viewer displays
- [ ] Toggle state persists when switching between documents
- [ ] Documents without summaries show helpful message
- [ ] No regressions in existing PDF viewer or citation navigation

---

## Story 2.8: Follow-Up Query Routing & Rate Limiting Strategy

As a **student and system administrator**,
I want **accurate follow-up query detection and robust rate limiting**,
so that **I can have natural conversations and the system scales reliably**.

### Acceptance Criteria

**Functional Requirements**:
1. Follow-up routing correctly identifies queries with specific context
2. If multiple regex routers match, second-stage semantic router or LLM filter disambiguates
3. Follow-up queries reuse chunk references from previous assistant message
4. System supports 2-3 OpenAI API keys with auto-switching
5. Redis bucket tracks token usage per API key
6. Rate limiting distributes load across keys to maximize throughput

**Integration Verification**:
1. Existing follow-up routing continues to work for basic queries
2. New routing handles complex follow-ups
3. Multiple API keys configured in environment variables
4. Redis tracks separate counters for each API key

**Quality Requirements**:
5. Multi-API-key switching adds <50ms overhead
6. Rate limiting prevents 429 errors from OpenAI

### Integration Verification

**IV1: Existing Routing Verification**
- Basic follow-up queries work ("elaborate on this")
- Quote finding route works correctly
- General Q&A route works correctly

**IV2: Multi-API-Key Integration Verification**
- Environment variables support `OPENAI_API_KEY_1`, `OPENAI_API_KEY_2`, `OPENAI_API_KEY_3`
- Redis keys track usage per API key
- System switches to key2 when key1 approaches 80% TPM limit
- All keys work for both embedding and generation calls

**IV3: Follow-Up Routing Verification**
- Test query: "elaborate on how this pertains to machine learning" â†’ routes to follow_up
- Test query: "find a quote about derivatives" â†’ routes to quote_finding
- Ambiguous queries trigger LLM tie-breaker

### Technical Notes

- **Integration Approach**:
  - Modify `router.py` to add second-stage LLM filter for ambiguous matches
  - Add regex pattern refinements for specific follow-up contexts
  - Create API key rotation logic in `semantic_search.py`
  - Modify `reserve_tokens()` to track usage per key
- **Existing Pattern Reference**: Current routing in `router.py`
- **Testing Focus**: Stress test with burst traffic to trigger key switching

### Definition of Done

- [ ] Test 10 follow-up queries with specific context, verify correct routing
- [ ] Test ambiguous queries, verify LLM tie-breaker logs appear
- [ ] Configure 2 API keys, verify auto-switching when key1 approaches limit
- [ ] Monitor OpenAI usage dashboard, verify load distributed across keys
- [ ] No 429 rate limit errors during stress testing
- [ ] No regressions in existing query routing

---

## Story 2.9: Beta Launch Readiness - Google OAuth, Final Testing, Documentation

As a **product owner and beta tester**,
I want **verified Google OAuth, comprehensive testing, and clear documentation**,
so that **beta launch is smooth and users have a great first experience**.

### Acceptance Criteria

**Functional Requirements**:
1. Google OAuth app verified with Google
2. OAuth flow does not display "unverified app" warning
3. Verification process documented in deployment runbook
4. Manual testing checklist 100% complete (all 29 test cases pass)
5. Deployment runbook updated with all new environment variables
6. Beta launch communication drafted

**Integration Verification**:
1. Google OAuth flow works end-to-end (signup, login)
2. All P0/P1 issues from ROUGH_FIXES.md resolved
3. Performance targets met (response times, ingestion times)

**Quality Requirements**:
4. All critical user flows tested
5. No console errors in frontend
6. All Heroku logs show structured format

### Integration Verification

**IV1: Google OAuth Verification**
- Test signup with Google â†’ no "unverified app" warning appears
- Test login with Google â†’ JWT cookie issued correctly
- Verify Google Cloud Console shows "Verified" status

**IV2: End-to-End Flow Verification**
- Execute full manual testing checklist
- All test cases pass without critical errors
- Performance measurements within targets

**IV3: Documentation Verification**
- Deployment runbook lists all required environment variables
- Rollback procedure documented and tested
- Beta communication templates ready for send

### Technical Notes

**Manual Testing Checklist** (Comprehensive - 29 Test Cases):

**Auth Flows (7 tests)**:
1. Signup with email/password â†’ verify email â†’ login
2. Signup with Google OAuth â†’ verify no warning â†’ login
3. Forgot password â†’ receive email â†’ reset â†’ login
4. Change email â†’ verify new email â†’ login
5. Change password â†’ logout â†’ login with new password
6. Login attempt limiting â†’ fail 5 times â†’ blocked â†’ wait 15min â†’ retry
7. Delete account â†’ confirm â†’ verify all data removed

**Document Management (6 tests)**:
8. Upload PDF â†’ verify ingestion â†’ query content
9. Upload DOCX â†’ verify ingestion â†’ query content
10. Upload PPTX â†’ verify ingestion â†’ query content
11. Upload scanned PDF (OCR) â†’ verify ingestion â†’ query content
12. Upload unsupported format â†’ verify error message
13. Delete document â†’ verify chunks removed from MongoDB

**Chat & RAG (7 tests)**:
14. Class chat â†’ verify max 3-5 citations
15. Document chat â†’ verify page-level citations â†’ click citation â†’ jump to page
16. Generate study guide â†’ verify special formatting â†’ save â†’ edit â†’ delete
17. Generate summary â†’ verify special formatting â†’ save
18. Find quote â†’ verify verbatim text â†’ save
19. Follow-up query ("elaborate on X") â†’ verify context preserved
20. No-hit query â†’ verify refinement suggestions appear

**UI/UX (6 tests)**:
21. Sidebar â†’ select class â†’ verify docs/chats/saved materials display
22. Sidebar â†’ recent chats â†’ verify class badges
23. Document viewer â†’ toggle PDF/Summary â†’ verify state persists
24. Formula rendering â†’ upload math PDF â†’ verify no layout breaks
25. Toast notifications â†’ trigger success/error â†’ verify bottom-right positioning
26. Mobile access â†’ verify blocking page appears

**Performance (3 tests)**:
27. Measure query response time (first token, full response)
28. Measure ingestion time (50-page, 200-page documents)
29. Measure sidebar class selection latency

### Definition of Done

- [ ] Google OAuth verification complete
- [ ] Manual testing checklist 100% complete (all 29 test cases pass)
- [ ] Deployment runbook updated with new env vars and rollback procedure
- [ ] Beta communication drafted and ready to send
- [ ] All P0/P1 issues resolved
- [ ] Performance targets met (documented measurements)
- [ ] Production logs clean (no errors for 24h period)

---
